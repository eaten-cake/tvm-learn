{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2fac5d1-e239-403c-b841-a91ad0a28d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax, topi\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import relax as R\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a8b8ac-f05b-42dd-a3ce-403b8f765536",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModule:\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((3, 4), \"float32\"), y: R.Tensor((3, 4), \"float32\")):\n",
    "        with R.dataflow():\n",
    "            lv0 = relax.op.multiply(x, y)\n",
    "            gv0 = relax.op.add(lv0, y)\n",
    "            R.output(gv0)\n",
    "        return gv0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08568e1a-b709-4d57-8c86-0bfe80ede005",
   "metadata": {},
   "outputs": [],
   "source": [
    "relax_func = MyModule[\"main\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af20723b-7ded-4bc4-8759-ed8fabf19889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: R.Tensor((3, 4), dtype=\"float32\")\n",
       "y: R.Tensor((3, 4), dtype=\"float32\")\n",
       "with R.dataflow():\n",
       "    lv0: R.Tensor((3, 4), dtype=\"float32\") = R.multiply(x, y)\n",
       "    gv0: R.Tensor((3, 4), dtype=\"float32\") = R.add(lv0, y)\n",
       "    R.output(gv0)\n",
       "gv0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_body = relax_func.body\n",
    "type(func_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b53cb8fe-0c3b-4eb0-9d4a-39dc7ea2cc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x: R.Tensor((3, 4), dtype=\"float32\")\n",
       "y: R.Tensor((3, 4), dtype=\"float32\")\n",
       "with R.dataflow():\n",
       "    lv0: R.Tensor((3, 4), dtype=\"float32\") = R.multiply(x, y)\n",
       "    gv0: R.Tensor((3, 4), dtype=\"float32\") = R.add(lv0, y)\n",
       "    R.output(gv0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_body.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33f28e5b-3c7e-4b1a-a8b6-d5e0824c5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataflow_block = func_body.blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9da6463-f84b-490c-86d7-40829e85e5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x: R.Tensor((3, 4), dtype=\"float32\")\n",
       "y: R.Tensor((3, 4), dtype=\"float32\")\n",
       "lv0: R.Tensor((3, 4), dtype=\"float32\") = R.multiply(x, y), lv0: R.Tensor((3, 4), dtype=\"float32\")\n",
       "y: R.Tensor((3, 4), dtype=\"float32\")\n",
       "gv0: R.Tensor((3, 4), dtype=\"float32\") = R.add(lv0, y)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataflow_block.bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad8a7546-389b-47df-bd07-2376ab254f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "binding = dataflow_block.bindings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f6796b8-0683-46fe-9d20-718b6fc8e6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(lv0, R.multiply(x, y))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binding.var, binding.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5feb9088-8a78-4e0d-b4e8-dd8e20991d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), y: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "    <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "        lv0: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(x, y)\n",
       "        gv0: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>ewise_fma(x, y, y)\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv0)\n",
       "    <span style=\"color: #008000; font-weight: bold\">return</span> gv0\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@relax.expr_functor.mutator\n",
    "class EwiseFMARewriter(relax.PyExprMutator):\n",
    "    def visit_call_(self, call):\n",
    "        call = self.visit_expr_post_order(call)\n",
    "        add_op = tvm.ir.Op.get(\"relax.add\")\n",
    "        multiply_op = tvm.ir.Op.get(\"relax.multiply\")\n",
    "        ewise_fma_op = tvm.ir.Op.get(\"relax.ewise_fma\")\n",
    "\n",
    "        if call.op != add_op:\n",
    "            return call\n",
    "\n",
    "        value = self.lookup_binding(call.args[0])\n",
    "        if not isinstance(value, relax.Call) or value.op != multiply_op:\n",
    "            return call\n",
    "\n",
    "        fma_call = relax.Call(\n",
    "            ewise_fma_op, [value.args[0], value.args[1], call.args[1]], None, None\n",
    "        )\n",
    "        return fma_call\n",
    "\n",
    "\n",
    "updated_fn = EwiseFMARewriter().visit_expr(MyModule[\"main\"])\n",
    "updated_fn.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92165df8-3ecd-4e84-b0cb-254ad4865837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), y: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "    <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "        gv0: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>ewise_fma(x, y, y)\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv0)\n",
       "    <span style=\"color: #008000; font-weight: bold\">return</span> gv0\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relax.analysis.remove_all_unused(updated_fn).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74df2750-3298-41a4-b5c7-7b15eef6d63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-29 00:51:57--  https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl\n",
      "Connecting to 127.0.0.1:7890... connected.\n",
      "Proxy request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/mlc-ai/web-data/main/models/fasionmnist_mlp_params.pkl [following]\n",
      "--2024-11-29 00:51:59--  https://raw.githubusercontent.com/mlc-ai/web-data/main/models/fasionmnist_mlp_params.pkl\n",
      "Connecting to 127.0.0.1:7890... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 407396 (398K) [application/octet-stream]\n",
      "Saving to: ‘fasionmnist_mlp_params.pkl.1’\n",
      "\n",
      "fasionmnist_mlp_par 100%[===================>] 397.85K   181KB/s    in 2.2s    \n",
      "\n",
      "2024-11-29 00:52:03 (181 KB/s) - ‘fasionmnist_mlp_params.pkl.1’ saved [407396/407396]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hide outputs\n",
    "!wget https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95fcce18-6ae0-469a-aedf-d46d3fd87cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "mlp_params = pkl.load(open(\"fasionmnist_mlp_params.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "219e33bf-f8e3-4762-8264-e7d67dc71686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(x, lv, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv1, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>])\n",
       "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu(lv2)\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>], axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            lv5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(lv3, lv4, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv5, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>])\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv6\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model():\n",
    "    bb = relax.BlockBuilder()\n",
    "    x = relax.Var(\"x\", relax.TensorStructInfo((1, 784), \"float32\"))\n",
    "    w0 = relax.const(mlp_params[\"w0\"], \"float32\")\n",
    "    b0 = relax.const(mlp_params[\"b0\"], \"float32\")\n",
    "    w1 = relax.const(mlp_params[\"w1\"], \"float32\")\n",
    "    b1 = relax.const(mlp_params[\"b1\"], \"float32\")\n",
    "    with bb.function(\"main\", [x]):\n",
    "        with bb.dataflow():\n",
    "            lv0 = bb.emit(relax.op.matmul(x, relax.op.permute_dims(w0)))\n",
    "            lv1 = bb.emit(relax.op.add(lv0, b0))\n",
    "            lv2 = bb.emit(relax.op.nn.relu(lv1))\n",
    "            lv3 = bb.emit(relax.op.matmul(lv2, relax.op.permute_dims(w1)))\n",
    "            lv4 = bb.emit(relax.op.add(lv3, b1))\n",
    "            gv = bb.emit_output(lv4)\n",
    "        bb.emit_func_output(gv)\n",
    "\n",
    "    return bb.get()\n",
    "\n",
    "MLPModel = create_model()\n",
    "MLPModel.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f503cfd-c24c-4252-87d5-3161f733bf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add0</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(x, w, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv, b)\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add1</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(x, w, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv, b)\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add0(x, lv, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>])\n",
       "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu(lv2)\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>], axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add1(lv3, lv4, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>])\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv6\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@relax.expr_functor.mutator\n",
    "class MatmulAddFusor(relax.PyExprMutator):\n",
    "    def __init__(self, mod: IRModule) -> None:\n",
    "        super().__init__()\n",
    "        self.mod_ = mod\n",
    "        # cache pre-defined ops\n",
    "        self.add_op = tvm.ir.Op.get(\"relax.add\")\n",
    "        self.matmul_op = tvm.ir.Op.get(\"relax.matmul\")\n",
    "        self.counter = 0\n",
    "\n",
    "    def transform(self) -> IRModule:\n",
    "        for global_var, func in self.mod_.functions.items():\n",
    "            if not isinstance(func, relax.Function):\n",
    "                continue\n",
    "            # avoid already fused primitive functions\n",
    "            if func.attrs is not None and \"Primitive\" in func.attrs.keys() and func.attrs[\"Primitive\"] != 0:\n",
    "                continue\n",
    "            updated_func = self.visit_expr(func)\n",
    "            updated_func = relax.analysis.remove_all_unused(updated_func)\n",
    "            self.builder_.update_func(global_var, updated_func)\n",
    "\n",
    "        return self.builder_.get()\n",
    "\n",
    "    def visit_call_(self, call):\n",
    "        call = self.visit_expr_post_order(call)\n",
    "\n",
    "        def match_call(node, op):\n",
    "            if not isinstance(node, relax.Call):\n",
    "                return False\n",
    "            return node.op == op\n",
    "\n",
    "        # pattern match matmul => add\n",
    "        if not match_call(call, self.add_op):\n",
    "            return call\n",
    "\n",
    "        value = self.lookup_binding(call.args[0])\n",
    "        if value is None:\n",
    "            return call\n",
    "\n",
    "        if not match_call(value, self.matmul_op):\n",
    "            return call\n",
    "\n",
    "        x = value.args[0]\n",
    "        w = value.args[1]\n",
    "        b = call.args[1]\n",
    "\n",
    "        # construct a new fused primitive function\n",
    "        param_x = relax.Var(\"x\" ,relax.TensorStructInfo(x.struct_info.shape, x.struct_info.dtype))\n",
    "        param_w = relax.Var(\"w\" ,relax.TensorStructInfo(w.struct_info.shape, w.struct_info.dtype))\n",
    "        param_b = relax.Var(\"b\" ,relax.TensorStructInfo(b.struct_info.shape, b.struct_info.dtype))\n",
    "\n",
    "        bb = relax.BlockBuilder()\n",
    "\n",
    "        fn_name = \"fused_matmul_add%d\" % (self.counter)\n",
    "        self.counter += 1\n",
    "        with bb.function(fn_name, [param_x, param_w, param_b]):\n",
    "            with bb.dataflow():\n",
    "                lv0 = bb.emit(relax.op.matmul(param_x, param_w))\n",
    "                gv = bb.emit_output(relax.op.add(lv0, param_b))\n",
    "            bb.emit_func_output(gv)\n",
    "\n",
    "        # Add Primitive attribute to the fused funtions\n",
    "        fused_fn = bb.get()[fn_name].with_attr(\"Primitive\", 1)\n",
    "        global_var = self.builder_.add_func(fused_fn, fn_name)\n",
    "\n",
    "        # construct call into the fused function\n",
    "        return relax.Call(global_var, [x, w, b], None, None)\n",
    "\n",
    "@tvm.ir.transform.module_pass(opt_level=2, name=\"MatmulAddFuse\")\n",
    "class FuseDenseAddPass:\n",
    "    \"\"\"The wrapper for the LowerTensorIR pass.\"\"\"\n",
    "    def transform_module(self, mod, ctx):\n",
    "        return MatmulAddFusor(mod).transform()\n",
    "\n",
    "\n",
    "MLPFused = FuseDenseAddPass()(MLPModel)\n",
    "MLPFused.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcb1440c-a987-4c3c-987a-9efe3c450bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax0, v_ax1], B[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
       "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add1</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax0, v_ax1], B[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
       "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">matmul</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_matmul_NN: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                v_i0, v_i1, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i0, v_k], B[v_k, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN[v_i0, v_i1])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i0, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_i1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">matmul1</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_matmul_NN: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                v_i0, v_i1, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i0, v_k], B[v_k, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN[v_i0, v_i1])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[v_i0, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[v_k, v_i1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">relu</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i0, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i0, v_i1])\n",
       "                compute[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(A[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">transpose</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_transpose: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_transpose&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax1, v_ax0])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_transpose[v_ax0, v_ax1])\n",
       "                T_transpose[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax1, v_ax0]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">transpose1</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_transpose: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_transpose&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax1, v_ax0])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_transpose[v_ax0, v_ax1])\n",
       "                T_transpose[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax1, v_ax0]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add0</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul, (x, w), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>add, (lv, b), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add1</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul1, (x, w), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>add1, (lv, b), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>transpose, (metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>],), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add0(x, lv, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>])\n",
       "            lv3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu, (lv2,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>transpose1, (metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>],), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add1(lv3, lv4, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>])\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv6\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@relax.expr_functor.mutator\n",
    "class LowerToTensorIR(relax.PyExprMutator):\n",
    "    def __init__(self, mod: IRModule, op_map) -> None:\n",
    "        super().__init__()\n",
    "        self.mod_ = mod\n",
    "        self.op_map = {\n",
    "            tvm.ir.Op.get(k): v for k, v in op_map.items()\n",
    "        }\n",
    "\n",
    "\n",
    "    def visit_call_(self, call):\n",
    "        call = self.visit_expr_post_order(call)\n",
    "\n",
    "        if call.op in self.op_map:\n",
    "            return self.op_map[call.op](self.builder_, call)\n",
    "        return call\n",
    "\n",
    "    def transform(self) -> IRModule:\n",
    "        for global_var, func in self.mod_.functions.items():\n",
    "            if not isinstance(func, relax.Function):\n",
    "                continue\n",
    "            updated_func = self.visit_expr(func)\n",
    "            self.builder_.update_func(global_var, updated_func)\n",
    "\n",
    "        return self.builder_.get()\n",
    "\n",
    "\n",
    "def map_matmul(bb, call):\n",
    "    x, w = call.args\n",
    "    return bb.call_te(topi.nn.matmul, x, w)\n",
    "\n",
    "def map_add(bb, call):\n",
    "    a, b = call.args\n",
    "    return bb.call_te(topi.add, a, b)\n",
    "\n",
    "def map_relu(bb, call):\n",
    "    return bb.call_te(topi.nn.relu, call.args[0])\n",
    "\n",
    "def map_transpose(bb, call):\n",
    "    return bb.call_te(topi.transpose, call.args[0], )\n",
    "\n",
    "op_map = {\n",
    "  \"relax.matmul\": map_matmul,\n",
    "  \"relax.add\": map_add,\n",
    "  \"relax.nn.relu\": map_relu,\n",
    "  \"relax.permute_dims\": map_transpose\n",
    "}\n",
    "\n",
    "@tvm.ir.transform.module_pass(opt_level=0, name=\"LowerToTensorIR\")\n",
    "class LowerToTensorIRPass:\n",
    "    \"\"\"The wrapper for the LowerTensorIR pass.\"\"\"\n",
    "    def transform_module(self, mod, ctx):\n",
    "        return LowerToTensorIR(mod, op_map).transform()\n",
    "\n",
    "\n",
    "MLPModelTIR = LowerToTensorIRPass()(MLPFused)\n",
    "MLPModelTIR.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39476941-0c38-4cc1-919e-fdf5ebfd1b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add0</span>(x: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add_intermediate: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        T_matmul_NN_intermediate <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                v_i0, v_i1, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(x[v_i0, v_k], w[v_k, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN_intermediate[v_i0, v_i1])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> x[v_i0, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> w[v_k, v_i1]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NN_intermediate[v_ax0, v_ax1], b[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add_intermediate[v_ax0, v_ax1])\n",
       "                T_add_intermediate[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN_intermediate[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> b[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add1</span>(x: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add_intermediate: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        T_matmul_NN_intermediate <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                v_i0, v_i1, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(x[v_i0, v_k], w[v_k, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN_intermediate[v_i0, v_i1])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> x[v_i0, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> w[v_k, v_i1]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NN_intermediate[v_ax0, v_ax1], b[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add_intermediate[v_ax0, v_ax1])\n",
       "                T_add_intermediate[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN_intermediate[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> b[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">relu</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_i0, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i0, v_i1])\n",
       "                compute[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(A[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">transpose</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_transpose: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_transpose&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax1, v_ax0])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_transpose[v_ax0, v_ax1])\n",
       "                T_transpose[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax1, v_ax0]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">transpose1</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_transpose: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_transpose&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax1, v_ax0])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_transpose[v_ax0, v_ax1])\n",
       "                T_transpose[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax1, v_ax0]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>transpose, (metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>],), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add0, (x, lv, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu, (lv2,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>transpose1, (metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>],), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add1, (lv3, lv4, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MLPModelFinal = relax.transform.FuseTIR()(MLPModelTIR)\n",
    "MLPModelFinal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dcab7b0-576e-47a2-a663-f6f308d4d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide outputs\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "img, label = next(iter(test_loader))\n",
    "img = img.reshape(1, 28, 28).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "388d9f0b-e9ba-43fe-b1eb-ebb0146c7c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Pullover\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "print(\"Class:\", class_names[label[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2cfc421-8e78-4bdc-ac10-19a6df36cb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModule Prediction: Pullover\n"
     ]
    }
   ],
   "source": [
    "ex = relax.build(MLPModelFinal, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "data_nd = tvm.nd.array(img.reshape(1, 784))\n",
    "\n",
    "nd_res = vm[\"main\"](data_nd)\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MLPModule Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813df5e-c333-45d1-ba94-9acc2a5f36bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
