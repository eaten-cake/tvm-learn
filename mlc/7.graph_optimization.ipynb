{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2fac5d1-e239-403c-b841-a91ad0a28d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax, topi\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import relax as R\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a8b8ac-f05b-42dd-a3ce-403b8f765536",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModule:\n",
    "    @R.function\n",
    "    def main(x: R.Tensor((3, 4), \"float32\"), y: R.Tensor((3, 4), \"float32\")):\n",
    "        with R.dataflow():\n",
    "            lv0 = relax.op.multiply(x, y)\n",
    "            gv0 = relax.op.add(lv0, y)\n",
    "            R.output(gv0)\n",
    "        return gv0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08568e1a-b709-4d57-8c86-0bfe80ede005",
   "metadata": {},
   "outputs": [],
   "source": [
    "relax_func = MyModule[\"main\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af20723b-7ded-4bc4-8759-ed8fabf19889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.relax.expr.SeqExpr"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_body = relax_func.body\n",
    "type(func_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53cb8fe-0c3b-4eb0-9d4a-39dc7ea2cc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x: R.Tensor((3, 4), dtype=\"float32\")\n",
       "y: R.Tensor((3, 4), dtype=\"float32\")\n",
       "with R.dataflow():\n",
       "    lv0: R.Tensor((3, 4), dtype=\"float32\") = R.multiply(x, y)\n",
       "    gv0: R.Tensor((3, 4), dtype=\"float32\") = R.add(lv0, y)\n",
       "    R.output(gv0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_body.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f28e5b-3c7e-4b1a-a8b6-d5e0824c5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataflow_block = func_body.blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9da6463-f84b-490c-86d7-40829e85e5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x: R.Tensor((3, 4), dtype=\"float32\")\n",
       "y: R.Tensor((3, 4), dtype=\"float32\")\n",
       "lv0: R.Tensor((3, 4), dtype=\"float32\") = R.multiply(x, y), lv0: R.Tensor((3, 4), dtype=\"float32\")\n",
       "y: R.Tensor((3, 4), dtype=\"float32\")\n",
       "gv0: R.Tensor((3, 4), dtype=\"float32\") = R.add(lv0, y)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataflow_block.bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad8a7546-389b-47df-bd07-2376ab254f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "binding = dataflow_block.bindings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6796b8-0683-46fe-9d20-718b6fc8e6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(lv0, R.multiply(x, y))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binding.var, binding.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5feb9088-8a78-4e0d-b4e8-dd8e20991d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), y: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "    <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "        lv0: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>multiply(x, y)\n",
       "        gv0: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>ewise_fma(x, y, y)\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv0)\n",
       "    <span style=\"color: #008000; font-weight: bold\">return</span> gv0\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@relax.expr_functor.mutator\n",
    "class EwiseFMARewriter(relax.PyExprMutator):\n",
    "    def visit_call_(self, call):\n",
    "        call = self.visit_expr_post_order(call)\n",
    "        add_op = tvm.ir.Op.get(\"relax.add\")\n",
    "        multiply_op = tvm.ir.Op.get(\"relax.multiply\")\n",
    "        ewise_fma_op = tvm.ir.Op.get(\"relax.ewise_fma\")\n",
    "\n",
    "        if call.op != add_op:\n",
    "            return call\n",
    "\n",
    "        value = self.lookup_binding(call.args[0])\n",
    "        if not isinstance(value, relax.Call) or value.op != multiply_op:\n",
    "            return call\n",
    "\n",
    "        fma_call = relax.Call(\n",
    "            ewise_fma_op, [value.args[0], value.args[1], call.args[1]], None, None\n",
    "        )\n",
    "        return fma_call\n",
    "\n",
    "\n",
    "updated_fn = EwiseFMARewriter().visit_expr(MyModule[\"main\"])\n",
    "updated_fn.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92165df8-3ecd-4e84-b0cb-254ad4865837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), y: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "    <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "        gv0: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>ewise_fma(x, y, y)\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv0)\n",
       "    <span style=\"color: #008000; font-weight: bold\">return</span> gv0\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relax.analysis.remove_all_unused(updated_fn).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74df2750-3298-41a4-b5c7-7b15eef6d63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-29 19:18:33--  https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/mlc-ai/web-data/main/models/fasionmnist_mlp_params.pkl [following]\n",
      "--2024-11-29 19:18:34--  https://raw.githubusercontent.com/mlc-ai/web-data/main/models/fasionmnist_mlp_params.pkl\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 407396 (398K) [application/octet-stream]\n",
      "Saving to: ‘fasionmnist_mlp_params.pkl.2’\n",
      "\n",
      "fasionmnist_mlp_par 100%[===================>] 397.85K  1.04MB/s    in 0.4s    \n",
      "\n",
      "2024-11-29 19:18:35 (1.04 MB/s) - ‘fasionmnist_mlp_params.pkl.2’ saved [407396/407396]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hide outputs\n",
    "!wget https://github.com/mlc-ai/web-data/raw/main/models/fasionmnist_mlp_params.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "219e33bf-f8e3-4762-8264-e7d67dc71686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(x, lv, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv1, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>])\n",
       "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu(lv2)\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>], axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            lv5: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(lv3, lv4, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv5, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>])\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv6\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model():\n",
    "    bb = relax.BlockBuilder()\n",
    "    x = relax.Var(\"x\", relax.TensorStructInfo((1, 784), \"float32\"))\n",
    "    w0 = relax.const(mlp_params[\"w0\"], \"float32\")\n",
    "    b0 = relax.const(mlp_params[\"b0\"], \"float32\")\n",
    "    w1 = relax.const(mlp_params[\"w1\"], \"float32\")\n",
    "    b1 = relax.const(mlp_params[\"b1\"], \"float32\")\n",
    "    with bb.function(\"main\", [x]):\n",
    "        with bb.dataflow():\n",
    "            lv0 = bb.emit(relax.op.matmul(x, relax.op.permute_dims(w0)))\n",
    "            lv1 = bb.emit(relax.op.add(lv0, b0))\n",
    "            lv2 = bb.emit(relax.op.nn.relu(lv1))\n",
    "            lv3 = bb.emit(relax.op.matmul(lv2, relax.op.permute_dims(w1)))\n",
    "            lv4 = bb.emit(relax.op.add(lv3, b1))\n",
    "            gv = bb.emit_output(lv4)\n",
    "        bb.emit_func_output(gv)\n",
    "\n",
    "    return bb.get()\n",
    "\n",
    "MLPModel = create_model()\n",
    "MLPModel.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f503cfd-c24c-4252-87d5-3161f733bf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add0</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(x, w, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv, b)\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add1</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul(x, w, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;void&quot;</span>)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>add(lv, b)\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>], axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add0(x, lv, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>])\n",
       "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu(lv2)\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>permute_dims(metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>], axes<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">None</span>)\n",
       "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add1(lv3, lv4, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>])\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv6\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@relax.expr_functor.mutator\n",
    "class MatmulAddFusor(relax.PyExprMutator):\n",
    "    def __init__(self, mod: IRModule) -> None:\n",
    "        super().__init__()\n",
    "        self.mod_ = mod\n",
    "        # cache pre-defined ops\n",
    "        self.add_op = tvm.ir.Op.get(\"relax.add\")\n",
    "        self.matmul_op = tvm.ir.Op.get(\"relax.matmul\")\n",
    "        self.counter = 0\n",
    "\n",
    "    def transform(self) -> IRModule:\n",
    "        for global_var, func in self.mod_.functions.items():\n",
    "            if not isinstance(func, relax.Function):\n",
    "                continue\n",
    "            # avoid already fused primitive functions\n",
    "            if func.attrs is not None and \"Primitive\" in func.attrs.keys() and func.attrs[\"Primitive\"] != 0:\n",
    "                continue\n",
    "            updated_func = self.visit_expr(func)\n",
    "            updated_func = relax.analysis.remove_all_unused(updated_func)\n",
    "            self.builder_.update_func(global_var, updated_func)\n",
    "\n",
    "        return self.builder_.get()\n",
    "\n",
    "    def visit_call_(self, call):\n",
    "        call = self.visit_expr_post_order(call)\n",
    "\n",
    "        def match_call(node, op):\n",
    "            if not isinstance(node, relax.Call):\n",
    "                return False\n",
    "            return node.op == op\n",
    "\n",
    "        # pattern match matmul => add\n",
    "        if not match_call(call, self.add_op):\n",
    "            return call\n",
    "\n",
    "        value = self.lookup_binding(call.args[0])\n",
    "        if value is None:\n",
    "            return call\n",
    "\n",
    "        if not match_call(value, self.matmul_op):\n",
    "            return call\n",
    "\n",
    "        x = value.args[0]\n",
    "        w = value.args[1]\n",
    "        b = call.args[1]\n",
    "\n",
    "        # construct a new fused primitive function\n",
    "        param_x = relax.Var(\"x\" ,relax.TensorStructInfo(x.struct_info.shape, x.struct_info.dtype))\n",
    "        param_w = relax.Var(\"w\" ,relax.TensorStructInfo(w.struct_info.shape, w.struct_info.dtype))\n",
    "        param_b = relax.Var(\"b\" ,relax.TensorStructInfo(b.struct_info.shape, b.struct_info.dtype))\n",
    "\n",
    "        bb = relax.BlockBuilder()\n",
    "\n",
    "        fn_name = \"fused_matmul_add%d\" % (self.counter)\n",
    "        self.counter += 1\n",
    "        with bb.function(fn_name, [param_x, param_w, param_b]):\n",
    "            with bb.dataflow():\n",
    "                lv0 = bb.emit(relax.op.matmul(param_x, param_w))\n",
    "                gv = bb.emit_output(relax.op.add(lv0, param_b))\n",
    "            bb.emit_func_output(gv)\n",
    "\n",
    "        # Add Primitive attribute to the fused funtions\n",
    "        fused_fn = bb.get()[fn_name].with_attr(\"Primitive\", 1)\n",
    "        global_var = self.builder_.add_func(fused_fn, fn_name)\n",
    "\n",
    "        # construct call into the fused function\n",
    "        return relax.Call(global_var, [x, w, b], None, None)\n",
    "\n",
    "@tvm.ir.transform.module_pass(opt_level=2, name=\"MatmulAddFuse\")\n",
    "class FuseDenseAddPass:\n",
    "    \"\"\"The wrapper for the LowerTensorIR pass.\"\"\"\n",
    "    def transform_module(self, mod, ctx):\n",
    "        return MatmulAddFusor(mod).transform()\n",
    "\n",
    "\n",
    "MLPFused = FuseDenseAddPass()(MLPModel)\n",
    "MLPFused.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcb1440c-a987-4c3c-987a-9efe3c450bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add</span>(lv: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(lv[v_ax0, v_ax1], b[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
       "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> b[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add1</span>(lv: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(lv[v_ax0, v_ax1], b[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[v_ax0, v_ax1])\n",
       "                T_add[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> b[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">matmul</span>(x: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_matmul_NN: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                v_i0, v_i1, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(x[v_i0, v_k], w[v_k, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN[v_i0, v_i1])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
       "                T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> x[v_i0, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> w[v_k, v_i1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">matmul1</span>(x: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_matmul_NN: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                v_i0, v_i1, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(x[v_i0, v_k], w[v_k, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN[v_i0, v_i1])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
       "                T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> x[v_i0, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> w[v_k, v_i1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">relu</span>(lv2: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(lv2[v_i0, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i0, v_i1])\n",
       "                compute[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(lv2[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">transpose</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_transpose: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_transpose&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax1, v_ax0])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_transpose[v_ax0, v_ax1])\n",
       "                T_transpose[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax1, v_ax0]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">transpose1</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_transpose: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_transpose&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax1, v_ax0])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_transpose[v_ax0, v_ax1])\n",
       "                T_transpose[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax1, v_ax0]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add0</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul, (x, w), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>add, (lv, b), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add1</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        R<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;Primitive&quot;</span>: <span style=\"color: #008000\">1</span>})\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>matmul1, (x, w), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>add1, (lv, b), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>transpose, (metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>],), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add0(x, lv, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>])\n",
       "            lv3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu, (lv2,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>transpose1, (metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>],), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add1(lv3, lv4, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>])\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv6\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@relax.expr_functor.mutator\n",
    "class LowerToTensorIR(relax.PyExprMutator):\n",
    "    def __init__(self, mod: IRModule, op_map) -> None:\n",
    "        super().__init__()\n",
    "        self.mod_ = mod\n",
    "        self.op_map = {\n",
    "            tvm.ir.Op.get(k): v for k, v in op_map.items()\n",
    "        }\n",
    "\n",
    "\n",
    "    def visit_call_(self, call):\n",
    "        call = self.visit_expr_post_order(call)\n",
    "\n",
    "        if call.op in self.op_map:\n",
    "            return self.op_map[call.op](self.builder_, call)\n",
    "        return call\n",
    "\n",
    "    def transform(self) -> IRModule:\n",
    "        for global_var, func in self.mod_.functions.items():\n",
    "            if not isinstance(func, relax.Function):\n",
    "                continue\n",
    "            updated_func = self.visit_expr(func)\n",
    "            self.builder_.update_func(global_var, updated_func)\n",
    "\n",
    "        return self.builder_.get()\n",
    "\n",
    "\n",
    "def map_matmul(bb, call):\n",
    "    x, w = call.args\n",
    "    return bb.call_te(topi.nn.matmul, x, w)\n",
    "\n",
    "def map_add(bb, call):\n",
    "    a, b = call.args\n",
    "    return bb.call_te(topi.add, a, b)\n",
    "\n",
    "def map_relu(bb, call):\n",
    "    return bb.call_te(topi.nn.relu, call.args[0])\n",
    "\n",
    "def map_transpose(bb, call):\n",
    "    return bb.call_te(topi.transpose, call.args[0], )\n",
    "\n",
    "op_map = {\n",
    "  \"relax.matmul\": map_matmul,\n",
    "  \"relax.add\": map_add,\n",
    "  \"relax.nn.relu\": map_relu,\n",
    "  \"relax.permute_dims\": map_transpose\n",
    "}\n",
    "\n",
    "@tvm.ir.transform.module_pass(opt_level=0, name=\"LowerToTensorIR\")\n",
    "class LowerToTensorIRPass:\n",
    "    \"\"\"The wrapper for the LowerTensorIR pass.\"\"\"\n",
    "    def transform_module(self, mod, ctx):\n",
    "        return LowerToTensorIR(mod, op_map).transform()\n",
    "\n",
    "\n",
    "MLPModelTIR = LowerToTensorIRPass()(MLPFused)\n",
    "MLPModelTIR.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39476941-0c38-4cc1-919e-fdf5ebfd1b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import relax as R</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add0</span>(x: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add_intermediate: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        T_matmul_NN_intermediate <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                v_i0, v_i1, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(x[v_i0, v_k], w[v_k, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN_intermediate[v_i0, v_i1])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
       "                T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> x[v_i0, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> w[v_k, v_i1]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NN_intermediate[v_ax0, v_ax1], b[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add_intermediate[v_ax0, v_ax1])\n",
       "                T_add_intermediate[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN_intermediate[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> b[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">fused_matmul_add1</span>(x: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), w: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>),), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_add_intermediate: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        T_matmul_NN_intermediate <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                v_i0, v_i1, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(x[v_i0, v_k], w[v_k, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN_intermediate[v_i0, v_i1])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>)\n",
       "                T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN_intermediate[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> x[v_i0, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> w[v_k, v_i1]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NN_intermediate[v_ax0, v_ax1], b[v_ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add_intermediate[v_ax0, v_ax1])\n",
       "                T_add_intermediate[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN_intermediate[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> b[v_ax1]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">relu</span>(lv2: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">1</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                v_i0, v_i1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(lv2[v_i0, v_i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i0, v_i1])\n",
       "                compute[v_i0, v_i1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(lv2[v_i0, v_i1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0.0</span>))\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">transpose</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_transpose: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">784</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_transpose&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax1, v_ax0])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_transpose[v_ax0, v_ax1])\n",
       "                T_transpose[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax1, v_ax0]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func(private<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">transpose1</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), T_transpose: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> ax0, ax1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">128</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_transpose&quot;</span>):\n",
       "                v_ax0, v_ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[v_ax1, v_ax0])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_transpose[v_ax0, v_ax1])\n",
       "                T_transpose[v_ax0, v_ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[v_ax1, v_ax0]\n",
       "\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">784</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>):\n",
       "        cls <span style=\"color: #AA22FF; font-weight: bold\">=</span> Module\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>transpose, (metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">0</span>],), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">784</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add0, (x, lv, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">1</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu, (lv2,), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            lv4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>transpose1, (metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">2</span>],), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            gv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(cls<span style=\"color: #AA22FF; font-weight: bold\">.</span>fused_matmul_add1, (lv3, lv4, metadata[<span style=\"color: #BA2121\">&quot;relax.expr.Constant&quot;</span>][<span style=\"color: #008000\">3</span>]), out_sinfo<span style=\"color: #AA22FF; font-weight: bold\">=</span>R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">10</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>))\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "\n",
       "<span style=\"color: #007979; font-style: italic\"># Metadata omitted. Use show_meta=True in script() method to show it.</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MLPModelFinal = relax.transform.FuseTIR()(MLPModelTIR)\n",
    "MLPModelFinal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dcab7b0-576e-47a2-a663-f6f308d4d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide outputs\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "img, label = next(iter(test_loader))\n",
    "img = img.reshape(1, 28, 28).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "388d9f0b-e9ba-43fe-b1eb-ebb0146c7c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Dress\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "print(\"Class:\", class_names[label[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2cfc421-8e78-4bdc-ac10-19a6df36cb58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModule Prediction: Dress\n"
     ]
    }
   ],
   "source": [
    "ex = relax.build(MLPModelFinal, target=\"llvm\")\n",
    "vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "data_nd = tvm.nd.array(img.reshape(1, 784))\n",
    "\n",
    "nd_res = vm[\"main\"](data_nd)\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MLPModule Prediction:\", class_names[pred_kind[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813df5e-c333-45d1-ba94-9acc2a5f36bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
