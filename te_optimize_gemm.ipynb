{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da1450ef-8d25-4816-8df3-4f0110643b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy running time: 0.004882s\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "import tvm.testing\n",
    "from tvm import te\n",
    "import numpy\n",
    "import timeit\n",
    "\n",
    "# 矩阵的大小\n",
    "# (M, K) x (K, N)\n",
    "# 可尝试不同的 shape，TVM 优化的性能有时比 numpy + MKL 更好\n",
    "M = 1024\n",
    "K = 1024\n",
    "N = 1024\n",
    "\n",
    "# TVM 默认张量数据类型\n",
    "dtype = \"float32\"\n",
    "\n",
    "# 你可能想调整 target 使其和你的任何 CPU 向量扩展匹配\n",
    "# 例如，如果你为 SIMD 用的是 Intel AVX2（高级向量扩展）ISA，把下面这行换成 `llvm -mcpu=core-avx2` 可以取得最佳性能（或者你所用 CPU 的具体类型）\n",
    "# 记住你用的是 llvm, 可以用 `llc --version` 命令来获取 CPU 类型，也可以查看 `/proc/cpuinfo` 来获取你处理器支持的更多扩展\n",
    "\n",
    "target = tvm.target.Target(target=\"llvm -mcpu=core-avx2\", host=\"llvm -mcpu=core-avx2\")\n",
    "dev = tvm.device(target.kind.name, 0)\n",
    "\n",
    "# 为测试随机生成的张量\n",
    "a = tvm.nd.array(numpy.random.rand(M, K).astype(dtype), dev)\n",
    "b = tvm.nd.array(numpy.random.rand(K, N).astype(dtype), dev)\n",
    "\n",
    "# 重复执行矩阵乘法以获得默认 numpy 实现的性能基线\n",
    "np_repeat = 100\n",
    "np_running_time = timeit.timeit(\n",
    "    setup=\"import numpy\\n\"\n",
    "    \"M = \" + str(M) + \"\\n\"\n",
    "    \"K = \" + str(K) + \"\\n\"\n",
    "    \"N = \" + str(N) + \"\\n\"\n",
    "    'dtype = \"float32\"\\n'\n",
    "    \"a = numpy.random.rand(M, K).astype(dtype)\\n\"\n",
    "    \"b = numpy.random.rand(K, N).astype(dtype)\\n\",\n",
    "    stmt=\"answer = numpy.dot(a, b)\",\n",
    "    number=np_repeat,\n",
    ")\n",
    "print(\"Numpy running time: %fs\" % (np_running_time / np_repeat))\n",
    "\n",
    "answer = numpy.dot(a.numpy(), b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ed620de-dcb1-49c5-8153-6258b674b632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none: 2.316857\n"
     ]
    }
   ],
   "source": [
    "# 用 TE的TVM矩阵乘法\n",
    "k = te.reduce_axis((0, K), \"k\")\n",
    "A = te.placeholder((M, K), name=\"A\")\n",
    "B = te.placeholder((K, N), name=\"B\")\n",
    "C = te.compute((M, N), lambda x, y: te.sum(A[x, k] * B[k, y], axis=k), name=\"C\")\n",
    "\n",
    "# 默认schdule\n",
    "s = te.create_schedule(C.op)\n",
    "func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "\n",
    "c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
    "func(a, b, c)\n",
    "tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "def evaluate_operation(s, vars, target, name, optimization, log):\n",
    "    func = tvm.build(s, [A, B, C], target=target, name=\"mmult\")\n",
    "    assert func\n",
    "\n",
    "    c = tvm.nd.array(numpy.zeros((M, N), dtype=dtype), dev)\n",
    "    func(a, b, c)\n",
    "    tvm.testing.assert_allclose(c.numpy(), answer, rtol=1e-5)\n",
    "\n",
    "    evaluator = func.time_evaluator(func.entry_name, dev, number=10)\n",
    "    mean_time = evaluator(a, b, c).mean\n",
    "    print(\"%s: %f\" % (optimization, mean_time))\n",
    "    log.append((optimization, mean_time))\n",
    "\n",
    "log = []\n",
    "\n",
    "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"none\", log=log) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cd43fd5-b1c1-4e45-85b3-b2e46ea8f105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
      "        for x, y in T.grid(1024, 1024):\n",
      "            C_1 = T.Buffer((1048576,), data=C.data)\n",
      "            C_1[x * 1024 + y] = T.float32(0)\n",
      "            for k in range(1024):\n",
      "                cse_var_2: T.int32 = x * 1024\n",
      "                cse_var_1: T.int32 = cse_var_2 + y\n",
      "                A_1 = T.Buffer((1048576,), data=A.data)\n",
      "                B_1 = T.Buffer((1048576,), data=B.data)\n",
      "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[cse_var_2 + k] * B_1[k * 1024 + y]\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b542c53c-f0ff-49ae-af1a-05fe43300d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocking: 0.129333\n"
     ]
    }
   ],
   "source": [
    "bn = 32\n",
    "\n",
    "# 通过循环切分实现块级化\n",
    "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], bn, bn)\n",
    "(k,) = s[C].op.reduce_axis\n",
    "ko, ki = s[C].split(k, factor=4)\n",
    "\n",
    "# 将归约域提升到块循环外\n",
    "s[C].reorder(xo, yo, ko, ki, xi, yi)\n",
    "\n",
    "evaluate_operation(s, [A, B, C], target=target, name=\"mmult\", optimization=\"blocking\", log=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f74c85-e380-48d4-a842-9ce0d5aac975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer((1024, 1024), \"float32\"), B: T.Buffer((1024, 1024), \"float32\"), C: T.Buffer((1024, 1024), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
      "        for x_outer, y_outer in T.grid(32, 32):\n",
      "            C_1 = T.Buffer((1048576,), data=C.data)\n",
      "            for x_inner_init, y_inner_init in T.grid(32, 32):\n",
      "                C_1[x_outer * 32768 + x_inner_init * 1024 + y_outer * 32 + y_inner_init] = T.float32(0)\n",
      "            for k_outer, k_inner, x_inner, y_inner in T.grid(256, 4, 32, 32):\n",
      "                cse_var_3: T.int32 = y_outer * 32\n",
      "                cse_var_2: T.int32 = x_outer * 32768 + x_inner * 1024\n",
      "                cse_var_1: T.int32 = cse_var_2 + cse_var_3 + y_inner\n",
      "                A_1 = T.Buffer((1048576,), data=A.data)\n",
      "                B_1 = T.Buffer((1048576,), data=B.data)\n",
      "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[cse_var_2 + k_outer * 4 + k_inner] * B_1[k_outer * 4096 + k_inner * 1024 + cse_var_3 + y_inner]\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d2349-7ea9-40d7-8bde-2b8a1023766a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
